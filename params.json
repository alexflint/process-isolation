{"name":"Process Isolation in Python","tagline":"Elegant process isolation in pure python","body":"`process_isolation` is a simple and elegant python module that lets\r\nyou run python modules in child processes but interact with them like\r\nordinary python modules.\r\n\r\n### Installation\r\n\r\nProcess isolation is implemented in pure python so installation is simple:\r\n\r\n    $ pip install process_isolation\r\n\r\n### Quickstart\r\n\r\nLet's start with the hello world of process isolation:\r\n\r\n```python\r\nfrom process_isolation import import_isolated\r\nsys = import_isolated('sys')\r\nsys.stdout.write('Hello world\\n')\r\n```\r\n\r\nA few things happened here:\r\n\r\n1. We imported the `process_isolation` module.\r\n\r\n2. A child process was forked off from the main python process and the\r\n   `sys` module was imported into that process.\r\n\r\n3. The main python process requested that the child process run\r\n   `sys.stdout.write('Hello world\\n')`\r\n\r\n4. The child process wrote `Hello world` to standard output.\r\n\r\n\r\nOne reason to run code in an isolated process is to debug code that\r\nmight crash at the C level, such as due to a segmentation fault rather\r\nthan an ordinary python exception. Here is some dangerous code:\r\n\r\n```python\r\n# buggy.py:\r\n\r\nimport types\r\ndef dragons_here():\r\n    types.FunctionType(types.CodeType(0, 0, 1, 0, 'd\\x00\\x00S', (), (), (), '', '', 1, ''),{})()\r\n```\r\n\r\nRunning this code causes a hard abort (not a regular python exception),\r\nwhich makes it difficult to debug:\r\n\r\n```\r\n>>> import buggy\r\n>>> buggy.dragons_here()\r\nSegmentation fault: 11\r\n```\r\n\r\nHowever, inside an isolated process we can safely run this code without our\r\nentire python interpreter crashing:\r\n\r\n```python\r\nfrom process_isolation import import_isolated, ProcessTerminationError\r\nbuggy = import_isolated('buggy')\r\ntry:\r\n    buggy.dragons_here()\r\nexcept ProcessTerminationError as ex:\r\n    print 'There be dragons!'\r\n```\r\n\r\n### Using process isolation\r\n\r\n`process_isolation` tries to be invisible whenever possible. In many\r\ncases it is possible to simply replace\r\n\r\n    import X\r\n\r\nwith \r\n\r\n    X = import_isolated('X')\r\n\r\nand leave all other code unchanged. Internally, `process_isolation`\r\nshuttles data back and forward between the main python interpreter and\r\nthe forked child process. When you call a function from an isolated\r\nmodule, that function runs in the isolated child process.\r\n\r\n```python\r\nos = import_isolated('os')\r\nos.rmdir('/tmp/foo')  # this function will run in the isolated child process\r\n```\r\n\r\nThe same is true when you instantiate a class -- after all, a\r\nconstructor is really just a special kind of function.\r\n\r\n```python\r\ncollections = import_isolated('collections')\r\nmy_dict = collections.OrderedDict()\r\n```\r\n\r\nThis code creates an `OrderedDict` object residing in the isolated\r\nprocess. To make sure the isolated process really is isolated, the\r\n`OrderedDict` will stay in the child process forever. `my_dict` is\r\nactually a proxy object that will shuttle member calls back and forth\r\nto the child process. For all intents and purposes, you can treat\r\n`my_dict` just like a real `OrderedDict`:\r\n\r\n```python\r\nmy_dict['abc'] = 123\r\nprint my_dict['abc']\r\nprint my_dict.viewvalues()\r\nfor key,value in my_dict.iteritems():\r\n    print key,value\r\n\r\ntry:\r\n    x = my_dict['xyz']\r\nexcept KeyError:\r\n    print 'The dictionary does not contain xyz'\r\n```\r\n\r\nUnder the hood, each of these calls involves some shuttling of data\r\nback and forth between the child and server process. If anything were\r\nto crash along the way, you would get a `ProcessTerminatedError`\r\ninstead of a hard crash, but other than that, everything should work\r\nexactly as if there were no process isolation involved.\r\n\r\n### Copying objects between processes\r\n\r\nSometimes this proxying behaviour can be inconvenient or\r\ninefficient. To get a copy of the real object behind the proxy, use\r\n`byvalue`:\r\n\r\n```python\r\nfrom process_isolation import import_isolated, byvalue\r\ncollections = import_isolated('collections')\r\nproxy_to_a_dict = collections.OrderedDict({'fred':11, 'tom':12})\r\nthe_real_deal = byvalue(collections.OrderedDict({'fred':11, 'tom':12}))\r\n\r\nprint type(proxy_to_a_dict)\r\nprint type(the_real_deal)\r\n```\r\n\r\nThis will print:\r\n\r\n```\r\n>>> process_isolation.ObjectProxy\r\n>>> collections.OrderedDict\r\n```\r\n\r\n`byvalue` copies an object from the child process to the main\r\npython interpreter, with the usual semantics of deep copies. Any\r\nreferences to the original object will continue to refer to the\r\noriginal object. If the original object is changed, those changes will\r\nnot show up in the copy residing in main python interpreter, and vice\r\nversa.\r\n\r\nNote that all calls to members of `the_real_deal` will now execute in\r\nthe main python interpreter, so if one of those members causes a\r\nsegfault then the main python interpreter will crash, just as if you\r\nran the whole thing without involving `process_isolation` at all.\r\n\r\n### Why process isolation?\r\n\r\n**Dealing with misbehaving C modules**\r\n\r\nWe originally built `process_isolation` to help benchmark a computer\r\nvision library written in C. We had built a python interface to the\r\nunderlying C library using boost python and we wanted to use python to\r\nmanage the datasets, accumulate success rates, generate reports, and\r\nso on. During development, it was not uncommon for our C library to\r\ncrash from time to time, but instead of getting an empty report\r\nwhenever any one test cases caused a crash, we wanted to record\r\nexactly which inputs caused the crash, and then continue to run the\r\nremaining tests. We built `process_isolation` and used it to run all\r\nthe computer vision code in an isolated process, which allowed us to\r\ngive detailed error reports when something went wrong at the C level,\r\nand to continue running the remaining tests afterwards.\r\n\r\nWe were also running our computer vision code interactively from\r\nipython. However, importing the computer vision module directly meant\r\nthat a crash at the C level would destroyed the entire ipython session\r\nand all the working variables along with it. Anyone who has done\r\ninteractive experiments with numerical software will appreciate the\r\nfrustration of losing an hour of carefully constructed matrices just\r\nbefore the command that would have completed whatever experiment was\r\nbeing run. Using `process_isolation` from ipython avoided this\r\npossibility in a very robust way. At worst case, a command would raise\r\na `ProcessTerminationError`, but all the variables and other session\r\nstate would remain intact.\r\n\r\n**Running untrusted code**\r\n\r\nAlthough there are many ways of running untrusted code in python, the\r\nmost secure way is to use a restricted environment enforced by the\r\noperating system. `process_isolation` is ideal for running some code\r\nin a subprocess. Here is how to create a `chroot` jail. \r\n\r\nFirst we create an \"untrusted\" module to experiment with.\r\n\r\n```python\r\n# untrusted.py: untrusted code lives here\r\nimport os\r\ndef ls_root():\r\n    return os.listdir('/')\r\n```\r\n\r\nNext we set up the chroot jail. Note that this code must be run with\r\nsuperuser priveleges because the `chroot` system call requires\r\nsuperuser priveleges.\r\n\r\n```python\r\n# run_untrusted_code.py\r\nimport os\r\nimport process_isolation\r\n\r\n# Start a subprocess but do not import the untrusted module until we've installed the chroot jail\r\ncontext = process_isolation.default_context()\r\ncontext.ensure_started()\r\n\r\n# Create a directoy in which to jail the untrusted module\r\nos.mkdir('/tmp/chroot_jail')\r\n\r\n# Create a file inside the chroot so that we can recognize the jail when we see it\r\nwith open('/tmp/chroot_jail/you_are_in_jail_muahaha','w'):\r\n    pass\r\n\r\ntry:\r\n    # Install the chroot\r\n    context.client.call(os.chroot, '/tmp/chroot_jail')\r\nexcept OSError:\r\n    print 'This script must be run with superuser priveleges'\r\n\r\n# Now we can safely import and run the untrusted module\r\nuntrusted = context.load_module('untrusted', path=['.'])\r\nprint untrusted.ls_root()\r\n\r\n# Clean up\r\nos.remove('/tmp/chroot_jail/you_are_in_jail_muahaha')\r\nos.rmdir('/tmp/chroot_jail')\r\n```\r\n\r\n```python\r\n$ sudo python run_untrusted_code.py\r\n['you_are_in_jail_muahaha']\r\n```\r\n\r\n<!--\r\n\r\n**Reloading binary modules**\r\n\r\nCheck back soon\r\n\r\n**Running unittests in separate processes**\r\n\r\nCheck back soon\r\n\r\n### Under the hood\r\n\r\nCheck back soon\r\n\r\n-->\r\n","google":"UA-36566659-2","note":"Don't delete this file! It's used internally to help with page regeneration."}